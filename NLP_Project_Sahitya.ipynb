{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sahitya Chalamchala (Venkata Sahitya) \n",
    "### 801019292\n",
    "\n",
    "## Neural Machine Translation (German-English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a raw text file and splitting the file into English and German Sentences:\n",
    "The file is formatted in such a way that the English-German pairs align properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    file = open(fname, mode='rt', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    sentences = text.strip().split('\\n')\n",
    "    sentences = [i.split('\\t') for i in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file(\"deu.txt\")\n",
    "deu_eng = split_text(data)\n",
    "deu_eng = array(deu_eng)\n",
    "#print(deu_eng)\n",
    "deu_eng = deu_eng[:50000,:] #reducing the sample size due to computational limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing punctuation and converting the text to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_eng[:,0] = [sen.translate(str.maketrans('', '', string.punctuation)) for sen in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [sen.translate(str.maketrans('', '', string.punctuation)) for sen in deu_eng[:,1]]\n",
    "\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
    "# deu_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before sending the sentences as it is to the model, it is required to convert the text into a format understandable by the machine i.e., numbers.\n",
    "\n",
    "### Converting the sentences into vectors (sequence of integers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size:  6361\n",
      "German Vocabulary size:  10597\n"
     ]
    }
   ],
   "source": [
    "eng_tokenize = tokenize(deu_eng[:, 0])\n",
    "eng_vocab = len(eng_tokenize.word_index) + 1\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size:','', eng_vocab)\n",
    "deu_tokenize = tokenize(deu_eng[:, 1])\n",
    "deu_vocab = len(deu_tokenize.word_index) + 1\n",
    "deu_length = 8\n",
    "print('German Vocabulary size:','', deu_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding the sentences of both the languages to an equal length by adding 0s at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_encoder(tokenizer, length, lines):\n",
    "    padd= tokenizer.texts_to_sequences(lines)\n",
    "    padd= pad_sequences(padd, maxlen=length, padding='post')\n",
    "    return padd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test sets with a validation size of 20% and a train size of 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data preparation\n",
    "train_X = pad_encoder(deu_tokenize, deu_length, train[:, 1])\n",
    "train_Y = pad_encoder(eng_tokenize, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data preparation\n",
    "test_X = pad_encoder(deu_tokenize, deu_length, test[:, 1])\n",
    "test_Y = pad_encoder(eng_tokenize, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Machine Translation Model built on Seq2Seq architeture using Sequential model from the Keras library. The encoder consists of an Embedding layer and an LSTM layer. The decoder consists of an LSTM layer and a Dense layer with \"softmax\" as the activation function and optimizer used here is the recommended optimizer for neural networks: RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMT model with encoder and decoder \n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential() \n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of 'sparse_categorical_crossentropy'  loss function instead of one-hot encoding is recommended here because of memory/computational limitations and also on such a large data one-hot encoding will consume a lot of space. \n",
    "'sparse_categorical_crossentropy' will retain the original format of data which is another advantage over one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sahit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(deu_vocab, eng_vocab, deu_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model:\n",
    "I have currently trained my model for 30 epochs with a batch size of 512. These parameters can be changed for multiple runs. \n",
    "To evaluate the model's performance I have used ModelCheckpoint() that will save my model to a file ('Nlp.nmt.oct.2019') and check the validation loss on every cycle and save the model with the lowest validation loss. It will log the imporvement of my model in every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sahit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\sahit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 355s 11ms/step - loss: 3.5016 - val_loss: 2.9352\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.93516, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 220s 7ms/step - loss: 2.8594 - val_loss: 2.8375\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.93516 to 2.83750, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 215s 7ms/step - loss: 2.7194 - val_loss: 2.7176\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.83750 to 2.71759, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 240s 7ms/step - loss: 2.5433 - val_loss: 2.5697\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.71759 to 2.56973, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 240s 7ms/step - loss: 2.3969 - val_loss: 2.4508\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.56973 to 2.45075, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 210s 7ms/step - loss: 2.2590 - val_loss: 2.3384\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.45075 to 2.33836, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 233s 7ms/step - loss: 2.1418 - val_loss: 2.2773\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.33836 to 2.27733, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 208s 7ms/step - loss: 2.0301 - val_loss: 2.1879\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.27733 to 2.18789, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 239s 7ms/step - loss: 1.9191 - val_loss: 2.1642\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.18789 to 2.16420, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 211s 7ms/step - loss: 1.8170 - val_loss: 2.0303\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.16420 to 2.03029, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 213s 7ms/step - loss: 1.7113 - val_loss: 1.9519\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.03029 to 1.95194, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 232s 7ms/step - loss: 1.6119 - val_loss: 1.8929\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.95194 to 1.89290, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 244s 8ms/step - loss: 1.5142 - val_loss: 1.8416\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.89290 to 1.84158, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 228s 7ms/step - loss: 1.4223 - val_loss: 1.7892\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.84158 to 1.78921, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 231s 7ms/step - loss: 1.3339 - val_loss: 1.7259\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.78921 to 1.72592, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 225s 7ms/step - loss: 1.2488 - val_loss: 1.6905\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.72592 to 1.69054, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 240s 7ms/step - loss: 1.1704 - val_loss: 1.6421\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.69054 to 1.64208, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 228s 7ms/step - loss: 1.0921 - val_loss: 1.6071\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.64208 to 1.60706, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 219s 7ms/step - loss: 1.0213 - val_loss: 1.5787\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.60706 to 1.57874, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 210s 7ms/step - loss: 0.9511 - val_loss: 1.5529\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.57874 to 1.55293, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 225s 7ms/step - loss: 0.8855 - val_loss: 1.5184\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.55293 to 1.51838, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 222s 7ms/step - loss: 0.8239 - val_loss: 1.4858\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.51838 to 1.48584, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 240s 7ms/step - loss: 0.7651 - val_loss: 1.4755\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.48584 to 1.47549, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 241s 8ms/step - loss: 0.7078 - val_loss: 1.4585\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.47549 to 1.45848, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 242s 8ms/step - loss: 0.6556 - val_loss: 1.4385\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.45848 to 1.43848, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 223s 7ms/step - loss: 0.6052 - val_loss: 1.4348\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.43848 to 1.43484, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 214s 7ms/step - loss: 0.5596 - val_loss: 1.4126\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.43484 to 1.41264, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 207s 6ms/step - loss: 0.5144 - val_loss: 1.4017\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.41264 to 1.40167, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 210s 7ms/step - loss: 0.4724 - val_loss: 1.3988\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.40167 to 1.39877, saving model to Nlp.nmt.oct.2019\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 216s 7ms/step - loss: 0.4334 - val_loss: 1.3914\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.39877 to 1.39139, saving model to Nlp.nmt.oct.2019\n"
     ]
    }
   ],
   "source": [
    "filename = 'Nlp.nmt.oct.2019'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(train_X, train_Y.reshape(train_Y.shape[0], train_Y.shape[1], 1), \n",
    "          epochs=30, batch_size=512, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions based on trained data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Nlp.nmt.oct.2019') # best-saved model obtained from training \n",
    "pclass = model.predict_classes(test_X.reshape((test_X.shape[0],test_X.shape[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(size, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == size:\n",
    "            return word\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr= []\n",
    "for i in pclass:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        k = word_vector(i[j], eng_tokenize)\n",
    "        if j > 0:\n",
    "            if (k == word_vector(i[j-1], eng_tokenize)) or (k == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(k)\n",
    "             \n",
    "        else:\n",
    "            if(k == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(k)            \n",
    "        \n",
    "    arr.append(' '.join(temp))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you need to wake up</td>\n",
       "      <td>you must be awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel old</td>\n",
       "      <td>i feel bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im sorry tom</td>\n",
       "      <td>im sorry for tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hide the money</td>\n",
       "      <td>is the money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is someone calling me</td>\n",
       "      <td>help me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>you should work hard</td>\n",
       "      <td>you should work hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tom has a big problem</td>\n",
       "      <td>tom has a big hero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>he lives with his mom</td>\n",
       "      <td>he lives his  cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>whats toms job</td>\n",
       "      <td>what is toms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i dont want to drive</td>\n",
       "      <td>i dont want to go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tom will fail</td>\n",
       "      <td>tom will win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tom phoned</td>\n",
       "      <td>tom obeyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lock the door</td>\n",
       "      <td>lock the door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>its not good</td>\n",
       "      <td>its not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i love soul food</td>\n",
       "      <td>i love rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   actual                 predicted\n",
       "0     you need to wake up     you must be awake    \n",
       "1              i feel old           i feel bad     \n",
       "2            im sorry tom      im sorry for tom    \n",
       "3          hide the money         is the money     \n",
       "4   is someone calling me             help me      \n",
       "5    you should work hard  you should work hard    \n",
       "6   tom has a big problem     tom has a big hero   \n",
       "7   he lives with his mom      he lives his  cat   \n",
       "8          whats toms job         what is toms     \n",
       "9    i dont want to drive      i dont want to go   \n",
       "10          tom will fail         tom will win     \n",
       "11             tom phoned          tom obeyed      \n",
       "12          lock the door        lock the door     \n",
       "13           its not good         its not good     \n",
       "14       i love soul food          i love rock     "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'actual' : test[:,0], 'predicted' : arr})\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "df.head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>let me see that list</td>\n",
       "      <td>let me do it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>tom hated mary</td>\n",
       "      <td>tom ignored mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7878</th>\n",
       "      <td>tom dialed 911</td>\n",
       "      <td>tom checked his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8609</th>\n",
       "      <td>throw it to me</td>\n",
       "      <td>give it to me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>enough is enough</td>\n",
       "      <td>is it enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985</th>\n",
       "      <td>i got it for free</td>\n",
       "      <td>i will it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>im going downtown</td>\n",
       "      <td>im am in the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>how did this all start</td>\n",
       "      <td>how did it begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>its made of leather</td>\n",
       "      <td>this is for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>come back soon</td>\n",
       "      <td>come back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>tom knew</td>\n",
       "      <td>tom hugged it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7948</th>\n",
       "      <td>did tom cause this</td>\n",
       "      <td>is tom retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>i ran like the wind</td>\n",
       "      <td>i ran like lightning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2861</th>\n",
       "      <td>he went for the doctor</td>\n",
       "      <td>he left the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>i didnt get his joke</td>\n",
       "      <td>i didnt no that joke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      actual                 predicted\n",
       "958     let me see that list          let me do it    \n",
       "207           tom hated mary     tom ignored mary     \n",
       "7878          tom dialed 911      tom checked his     \n",
       "8609          throw it to me         give it to me    \n",
       "1760        enough is enough         is it enough     \n",
       "6985       i got it for free            i will it     \n",
       "316        im going downtown          im am in the    \n",
       "2163  how did this all start      how did it begin    \n",
       "7640     its made of leather          this is for     \n",
       "4396          come back soon           come back      \n",
       "706                 tom knew        tom hugged it     \n",
       "7948      did tom cause this       is tom retired     \n",
       "585      i ran like the wind  i ran like lightning    \n",
       "2861  he went for the doctor          he left the     \n",
       "95      i didnt get his joke   i didnt no that joke   "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>do you need a ride</td>\n",
       "      <td>can i sit you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>it is very small</td>\n",
       "      <td>its very small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>we can handle that</td>\n",
       "      <td>we can do it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>nobody believes you</td>\n",
       "      <td>no one believes you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>tom never changes</td>\n",
       "      <td>tom never complains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>i just emailed you</td>\n",
       "      <td>i just as a you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>tom is so stupid</td>\n",
       "      <td>tom is so stupid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>i found tom</td>\n",
       "      <td>i found tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>i met mary yesterday</td>\n",
       "      <td>i met yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>try and stop me</td>\n",
       "      <td>try to  me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>does that feel good</td>\n",
       "      <td>the students ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>do you like dancing</td>\n",
       "      <td>do you like to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>tom is a con man</td>\n",
       "      <td>tom is a con artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>why arent you there</td>\n",
       "      <td>why dont you there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>how do we stop tom</td>\n",
       "      <td>how can we stop tom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    actual                 predicted\n",
       "9985    do you need a ride         can i sit you    \n",
       "9986      it is very small       its very small     \n",
       "9987    we can handle that          we can do it    \n",
       "9988   nobody believes you   no one believes you    \n",
       "9989     tom never changes  tom never complains     \n",
       "9990    i just emailed you        i just as a you   \n",
       "9991      tom is so stupid      tom is so stupid    \n",
       "9992           i found tom          i found tom     \n",
       "9993  i met mary yesterday      i met yesterday     \n",
       "9994       try and stop me            try to  me    \n",
       "9995   does that feel good      the students ok     \n",
       "9996   do you like dancing        do you like to    \n",
       "9997      tom is a con man    tom is a con artist   \n",
       "9998   why arent you there    why dont you there    \n",
       "9999    how do we stop tom    how can we stop tom   "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicitions aren't accurate and can still be improved if the entire data is used instead of reducing the size and also by changing the parameters while training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
